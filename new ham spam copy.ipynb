{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binomial ham-spam classifier\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham=[]\n",
    "spam=[]\n",
    "\n",
    "for name in os.listdir(\"enron3/ham\"):\n",
    "    ham.append(name)\n",
    "for name in os.listdir(\"enron3/spam\"):\n",
    "    spam.append(name)\n",
    "len_of_ham=len(ham)\n",
    "\n",
    "len_of_spam=len(spam)\n",
    "\n",
    "prior_of_ham=len_of_ham/(len_of_ham+len_of_spam)\n",
    "\n",
    "prior_of_spam=len_of_spam/(len_of_ham+len_of_spam)\n",
    "#For testing data\n",
    "#for ham tesing\n",
    "wordcount={}\n",
    "ham_words={}\n",
    "for name in ham:\n",
    "    file1=open(\"enron3/ham\"+\"//\" + name,errors='ignore')\n",
    "    ham_words=Counter(file1.read().split()) \n",
    "    for item in ham_words:\n",
    "        \n",
    "        if item in wordcount:\n",
    "            wordcount[item]+=ham_words[item]\n",
    "        else:\n",
    "            wordcount[item]=0\n",
    "            wordcount[item]=ham_words[item]\n",
    "\n",
    "#print(wordcount)            \n",
    "ham_cp={}\n",
    "ham_count={}\n",
    "for item in wordcount:\n",
    "    ham_count[item]=0\n",
    "    for file in ham:\n",
    "        if item in open(\"enron3/ham\"+\"//\" + file,errors='ignore').read():\n",
    "            ham_count[item]+=1\n",
    "#calculating condiotional probablity:            \n",
    "       \n",
    "for item in wordcount:\n",
    "    ham_cp[item]=(ham_count[item]+1)/(len_of_ham + 2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for spam classifier counting if the words are present in each document\n",
    "wordcount2={}\n",
    "spam_words={}\n",
    "for name2 in spam:\n",
    "    file2=open(\"enron3/spam\"+\"//\" + name2,errors='ignore')\n",
    "    spam_words=Counter(file1.read().split()) \n",
    "    for item in spam_words:\n",
    "        if item in wordcount2:\n",
    "            wordcount2[item]+=spam_words[item]\n",
    "        else:\n",
    "            wordcount2[item]=0\n",
    "            wordcount2[item]=spam_words[item]   \n",
    "\n",
    "spam_cp={}\n",
    "spam_count={}\n",
    "for item in wordcount2:\n",
    "    spam_count[item]=0\n",
    "    for file in spam:\n",
    "        if item in open(\"enron3/spam\"+\"//\" + file,errors='ignore').read():\n",
    "            spam_count[item]+=1\n",
    "#calculating condiotional probablity:            \n",
    " \n",
    "for item in wordcount2:\n",
    "    spam_cp[item]=(spam_count[item]+1)/(len_of_spam + 2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data in bernoullis expansion:\n",
    "score_ham=2*math.log10(prior_of_ham)\n",
    "score_spam=2*math.log10(prior_of_spam)\n",
    "tp=0\n",
    "tn=0\n",
    "fp=0\n",
    "fn=0\n",
    "wordcount3={}\n",
    "for temp in os.listdir(\"enron4/ham\"):\n",
    "    \n",
    "    file3=open(\"enron4/ham\"+\"//\"+temp,errors='ignore')\n",
    "    \n",
    "    wordcount3=Counter(file3.read().split())\n",
    "    \n",
    "    for word in wordcount:\n",
    "        if word in wordcount3:\n",
    "            score_ham+=math.log10(ham_cp[word])\n",
    "        else:\n",
    "            score_ham+=math.log10(1-ham_cp[word])\n",
    "    \n",
    "    for word2 in wordcount2:\n",
    "        if word2 in wordcount3:\n",
    "                  score_spam+=math.log10(spam_cp[word2])\n",
    "        else:\n",
    "            score_spam+=math.log10(1-spam_cp[word2])\n",
    "    if(score_ham>score_spam):\n",
    "        tp+=1\n",
    "    else:\n",
    "        fp+=1\n",
    "wordcount3={}\n",
    "score_ham=2*math.log10(prior_of_ham)\n",
    "score_spam=2*math.log10(prior_of_spam)\n",
    "        \n",
    "    \n",
    "\n",
    "wordcount4={}\n",
    "\n",
    "score2_ham=2*math.log(prior_of_ham)\n",
    "score2_spam=2*math.log(prior_of_spam)\n",
    "\n",
    "for docs in os.listdir(\"enron4/spam\"):\n",
    "        file4=open(\"enron4/spam\"+\"//\"+docs,errors='ignore')\n",
    "        wordcount4=Counter(file4.read().split())\n",
    "        for word3 in wordcount:\n",
    "            if word3 in wordcount4:\n",
    "                score2_ham+=math.log10(ham_cp[word3])\n",
    "            else:\n",
    "                score2_ham+=math.log10(1-ham_cp[word3])\n",
    "    \n",
    "        for word4 in wordcount2:\n",
    "            if word4 in wordcount4:\n",
    "                      score2_spam+=math.log10(spam_cp[word4])\n",
    "            else:\n",
    "                      score2_spam+=math.log10(1-spam_cp[word4])\n",
    "        if(score2_ham<score2_spam):\n",
    "            tn+=1\n",
    "        else:\n",
    "            fn+=1\n",
    "        wordcount4={}\n",
    "        score2_ham=0\n",
    "        score2_spam=0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n"
     ]
    }
   ],
   "source": [
    "accuracy=(tp+tn)/(tp+tn+fp+fn)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
